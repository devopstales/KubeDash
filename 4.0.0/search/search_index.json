{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"What is KubeDash?","text":"<p>KubeDash is a general purpose, web-based UI for Kubernetes clusters. It allows users to observe applications running in the cluster and troubleshoot them, as well as manage the cluster itself.</p> <p>KubeDash was created to be a Kubernetes web UI that has the traditional functionality of other web UIs/dashboards available (i.e. to list and view resources) as well as other features.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Dark mode</li> <li>Manage any Kubernetes cluster.</li> <li>CPU and Memory metrics visualization.</li> <li>User management.<ul> <li>Role management for users based on templates</li> <li>Role management for SSO groups based on templates</li> </ul> </li> <li>Pod Debugging<ul> <li>Login to pod with UI based terminal</li> <li>View container logs in pods</li> </ul> </li> <li>Single sign-on integration with authentication and authorization</li> <li>Kubectl configuration generation<ul> <li>Generate OIDC based Kubernetes API authentication</li> <li>Generate Certificate based authentication</li> <li>kubectl plugin for easier config download</li> </ul> </li> <li>Dashboard Plugins<ul> <li>Docker Registry UI</li> <li>Hem Chart listing</li> <li>Cert-manager Plugin object visualization</li> </ul> </li> <li>Coming soon:<ul> <li>Gateway API Plugin for object visualization</li> <li>FluxCD Plugin object visualization</li> <li>trivy-operator integration to visualize vulnerability</li> </ul> </li> </ul>"},{"location":"contributing/","title":"Contribution Guidelines","text":"<p>This section has information on how to contribute to KubeDash. It assumes you have cloned this repository (or your own Github fork).</p> <p>Any contributions to the project are accepted under the terms of the project's license (Apache 2.0).</p>"},{"location":"contributing/#filing-an-issue-or-feature-request","title":"Filing an issue or feature request","text":"<p>Please use the project's issue tracker for filing any bugs you find or features you think are useful.</p>"},{"location":"contributing/#complex-contributions","title":"Complex contributions","text":"<p>If you have a complex contribution in mind (meaning changes in the architecture or a lot of LOC changed), it is advisable to first file a Github issue and discuss the implementation with the project's maintainers.</p>"},{"location":"contributing/#commit-guidelines","title":"Commit guidelines","text":"<p>For the general guidelines on making PRs/commits easier to review, please check out the conventionalcommits standard.</p>"},{"location":"development/auth0-minikube/","title":"Auth0 -&gt; k8s","text":"<p>Setup an Issuer via Auth0 to authenticate and authorize your k8s cluster</p>"},{"location":"development/auth0-minikube/#security-considerations","title":"Security Considerations","text":"<p>This tool allows for easy authentication of users for k8s. While we have followed best practices for the tool, there are still security considerations to be taken when setting up the actual pieces that handle authentication: - we are using the PKCE flow and thus do not need to support other flows. If the authentication application supports things like the Implicit Flow you could open yourself up to potential security risks. - if your setup issues refresh tokens you need to be aware that a refresh token allows a user to be authenticated indefinitely until the refresh token is revoked. If your setup does not issue refresh tokens there's nothing to worry about as this tool will still work and will require re-authentication any time the users access token expires.</p>"},{"location":"development/auth0-minikube/#auth0-setup","title":"Auth0 Setup","text":"<ol> <li>Go to https://manage.auth0.com/#/apis and create an API. This will represent the Kubernetes API. For this example, name it <code>minikube</code> and give it an identifier along the same lines <code>minikube</code>. Leave the signing to be RS256.</li> <li>Under the settings section of the newly created API scroll down to <code>Allow Offline Access</code>. Turn this option on if you wish to use Refresh Tokens. See Security Considerations for more details.</li> <li>Save the API Identifier (not to be confused with the Id) for later.</li> <li>Go to https://manage.auth0.com/#/applications and create an application. This will be the application that users login to when authenticating to interact with Kubernetes. Name it something like <code>minikube-login</code> and choose <code>Native</code> as the application type. This application type is used because the Authorization Code Grant Flow with PKCE is used by this tool and that flow will only work when the application type is <code>Native</code>.</li> <li>Under the settings section of the newly created Application, add <code>http://127.0.0.1:8000/callback, https://openidconnect.net/callback</code> to the <code>Allowed Callback URLs</code> section. This tool will be listening for a short period of time at that location when the user authenticates so it can handle receiving the needed information from Auth0.</li> <li>Scroll down to the bottom of the application settings, click on <code>Show Advanced Settings</code>, and click on <code>Grant Types</code>. Make sure to uncheck <code>Implicit</code> as the tool does not use that Grant Type and leaving it on could allow for flows different from PKCE. If you don't want to use refresh tokens make sure you uncheck the <code>Refresh Token</code> Grant Type. See Security Considerations for more details.</li> <li>Go to https://manage.auth0.com/#/extensions and find and install the <code>Auth0 Authorization Extension</code>. This will allow you to set up the groups and assign users to them.</li> <li>For this example, create two groups: <code>cluster-view</code> and <code>cluster-admin</code>. Assign them to your users.</li> <li>In the upper right hand corner, select your username and click <code>Configuration</code> and then scroll down to <code>Persistance</code>.</li> <li>Make sure the <code>Groups</code> slider is set to yes so the users groups will be stored in their profile. Scroll up and click <code>Publish Rule</code> so the information is store in their profiles.</li> </ol>"},{"location":"development/auth0-minikube/#_1","title":"???","text":"<ol> <li>On the menu on the left, go to Actions &gt; Library and select <code>Custom</code>.</li> <li>Enter a descriptive Name for your Action (for example, <code>Add user metadata to tokens</code>), select the <code>Login / Post Login</code> trigger because you\u2019ll be adding the Action to the Login flow, then select <code>Create</code>.</li> </ol> <p><pre><code>exports.onExecutePostLogin = async (event, api) =&gt; { \nconst namespace = 'https://my-app.example.com';\nif (event.authorization) { \napi.idToken.setCustomClaim(`${namespace}/groups`, user.grou); \napi.accessToken.setCustomClaim(`${namespace}/groups`, user.grou); \napi.user.setUserMetadata(`${namespace}/groups`, event.authorization.groups); \n} \n}\n</code></pre> 13. Make sure you've put in the client ID you saved from step 5 and save the rule. This rule is what adds the group a user was added to via the Authorization Extension to their access token. We will only add these groups to their token when they are authenticating against your <code>minikube-login</code> application.</p>"},{"location":"development/auth0-minikube/#test-connection","title":"Test connection","text":"<p>We can now test that we got everything right by using the OpenID Connect debugger. Browse to <code>https://openidconnect.net/</code>. Click the \"Configuration\" link, and fill in your <code>domain</code> from you Auth0 client settings, then click \"use auth discovery document\". Also fill in the client ID and Client secret. Hit \"save\" and then \"Start\". You should be prompted with a login box. </p>"},{"location":"development/auth0-minikube/#kubernetes-setup","title":"Kubernetes Setup","text":"<p>Kubernetes needs to be configured to validate tokens sent to it and also pull group information so it can apply roles. The settings for this are configured on the API server: </p> <pre><code>--authorization-mode=RBAC \\\n--oidc-issuer-url=\"https://joncarl.auth0.com/\" \\\n--oidc-client-id=minikube \\\n--oidc-username-claim=http://minikube/email \\\n--oidc-groups-claim=http://minikube/groups \\\n--oidc-groups-prefix=minikube-\n</code></pre> <ul> <li><code>authorization-mode</code> - this needs to be set to <code>RBAC</code> so that Kubernetes uses roles to provide authorization</li> <li><code>oidc-issuer-url</code> - this should be the URL of your Auth0 domain</li> <li><code>oidc-client-id</code> - the API client ID from step 3 of the Auth0 configuration. Do not confuse this with the application client ID. This id is what we refer to as the audience when you init k8s-pixy-auth.</li> <li><code>oidc-username-claim</code> - the token claim that the username will be pulled from. this must be set the claim the email is added to in the rule</li> <li><code>oidc-groups-claim</code> - the token claim that the users groups will be pulled from.</li> <li><code>oidc-groups-prefix</code> - the prefix that Kubernetes will add to each role from the token before matching it to a role in Kubernetes</li> </ul> <p>For minikube this can be configured as follows:</p> <pre><code>minikube start --extra-config=apiserver.authorization-mode=RBAC \\\n--extra-config=apiserver.oidc-issuer-url=\"https://joncarl.auth0.com/\" \\\n--extra-config=apiserver.oidc-client-id=minikube \\\n--extra-config=apiserver.oidc-username-claim=http://minikube/email \\\n--extra-config=apiserver.oidc-groups-claim=http://minikube/groups \\\n--extra-config=apiserver.oidc-groups-prefix=minikube-\n</code></pre> <p>The next step is to create groups. For this example we already have two groups on the Auth0 side: <code>cluster-admin</code> and <code>cluster-view</code>. To make these groups in Kubernetes, run the following: - <code>kubectl create clusterrolebinding auth0-cluster-view --clusterrole=view --group=minikube-cluster-view</code> - <code>kubectl create clusterrolebinding auth0-cluster-admin --clusterrole=cluster-admin --group=minikube-cluster-admin</code> Note that we added <code>minikube-</code> to the beginning of the <code>--group</code>. As mentioned above, Kubernetes will automatically prepend <code>minikube-</code> to the group name from the token (<code>cluster-admin</code> becomes <code>minikube-cluster-admin</code>) and then matches that group against the groups already in Kubernetes.</p>"},{"location":"development/auth0-minikube/#kube-config-setup","title":"Kube Config Setup","text":"<p>Now that we have the Auth0 and Kubernetes pieces set up, lets setup your Kube config. k8s-pixy-auth makes it really easy to get things set up with one command. Run the following and make sure your add in the variables you need instead of the example ones: <code>k8s-pixy-auth init --context-name \"minikube\" --issuer-endpoint \"https://joncarl.auth0.com\" --audience \"minikube\" --client-id \"QXV0aDAgaXMgaGlyaW5nISBhdXRoMC5jb20vY2FyZWVycyAK\"</code>. If you allowed offline access from step 2 you will need to add <code>--with-refresh-token</code> to the command arguments so that the refresh token is actuall used. If you want to see what happened in your kube config you should find that the context you passed into the init command has a new user with <code>-exec-auth</code> on the end. If you find the user in the file is should be setup similar to the following:</p> <pre><code>- name: minikube-exec-auth\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1beta1\n      args:\n      - auth\n      - --issuer-endpoint=https://joncarl.auth0.com\n      - --client-id=QXV0aDAgaXMgaGlyaW5nISBhdXRoMC5jb20vY2FyZWVycyAK\n      - --audience=minikube\n      command: /Users/joncarl/.k8s-pixy-auth/bin/k8s-pixy-auth\n</code></pre> <ul> <li><code>user.exec.command</code> is the pointing to the binary</li> <li><code>user.exec.args</code> are the different args passed into the binary </li> </ul> <p>You're all set! Run any command against kubernetes and it will open your browser for you to authenticate and then use that token to identify you when talking to Kubernetes. Your tokens are stored securely using Keyring, so once you initially authenticate it will store your tokens and ask you to re-auth if they expire. If you need to clear out saved tokens you'll need to figure out the secure backend that Keyring used and remove them from there.</p>"},{"location":"development/dbmigrate/","title":"Dbmigrate","text":""},{"location":"development/dbmigrate/#flask-db-migrate","title":"flask db migrate","text":"<p>It use Flask-Migrate that use alembic. In the source repo creates a <code>migrations</code> repo with the <code>alembic.ini</code> config</p> <pre><code>export FLASK_APP=kubedash\nflask db init\n\nflask db migrate -m \"users table\"\nflask db upgrade\n\nflask db migrate -m \"posts table\"\nflask db upgrade\n\nflask db history\n\nflask db downgrade\n</code></pre>"},{"location":"development/env/","title":"Programs","text":""},{"location":"development/env/#vscode","title":"VSCode","text":""},{"location":"development/env/#plugins","title":"Plugins","text":"<ul> <li>Remote Explorer</li> <li>Remote SSH</li> <li>Dev Containers</li> <li> <p>Cloud Code (google)</p> </li> <li> <p>Database Client</p> </li> <li> <p>Docker</p> </li> <li> <p>Kubernetes</p> </li> <li> <p>go</p> </li> <li>Python</li> <li>Pylance</li> <li>Python Debugger</li> <li>Python Environment Manager</li> <li>PlaywrightTest fo VSCode</li> <li>autoDocstring</li> <li>Better Jinja</li> <li>Jinja</li> <li>jinja2</li> </ul>"},{"location":"development/env/#python-venv","title":"Python venv","text":"<pre><code>python3 -m venv .venv\n</code></pre>"},{"location":"development/env/#skaffold","title":"skaffold","text":"<pre><code>brew install skaffold\n</code></pre>"},{"location":"development/registry-ui/","title":"Registry ui","text":"<pre><code>skopeo login --tls-verify=false 127.0.0.1:5000\nskopeo copy --dest-tls-verify=false docker://arm32v6/python:3.12-rc-alpine docker://127.0.0.1:5000/arm32v6/python:3.12-rc-alpine\nskopeo copy --dest-tls-verify=false --override-os=linux docker://python:3.12-rc-alpine docker://127.0.0.1:5000/python:3.12-rc-alpine\n\nskopeo copy --dest-tls-verify=false --override-os=linux docker://devopstales/registry-imega-test:1.0 docker://127.0.0.1:5000/registry-imega-test:1.0\nskopeo copy --dest-tls-verify=false --override-os=linux docker://devopstales/registry-imega-test:2.0 docker://127.0.0.1:5000/registry-imega-test:2.0\nskopeo copy --dest-tls-verify=false --override-os=linux docker://devopstales/registry-imega-test:3.0 docker://127.0.0.1:5000/registry-imega-test:3.0\nskopeo copy --dest-tls-verify=false --override-os=linux docker://devopstales/registry-imega-test:3.0 docker://127.0.0.1:5000/registry-imega-test:test\n\noras login --plain-http 127.0.0.1:5000\noras copy --to-plain-http ghcr.io/aquasecurity/trivy-db:2 127.0.0.1:5000/trivy-db:2\noras copy --to-plain-http ghcr.io/aquasecurity/trivy-java-db:1 127.0.0.1:5000/trivy-java-db:1\n\nhelm pull oci://registry-1.docker.io/bitnamicharts/redis --version 17.9.5\nhelm push redis-17.9.5.tgz OCI://127.0.0.1:5000/helm-charts\n\n# https://github.com/helm/helm/issues/6141\n\nCOSIGN_EXPERIMENTAL=1 cosign sign 127.0.0.1:5000/registry-imega-test:1.0\nCOSIGN_EXPERIMENTAL=1 cosign verify 127.0.0.1:5000/registry-imega-test:1.0\n\ntrivy i --format cosign-vuln 127.0.0.1:5000/registry-imega-test:1.0 &gt; image.sbom\ncosign attach sbom --sbom image.sbom 127.0.0.1:5000/registry-imega-test:1.0\n\nCOSIGN_EXPERIMENTAL=1 cosign sign --attachment sbom 127.0.0.1:5000/registry-imega-test:1.0\n</code></pre>"},{"location":"faq/technical/","title":"Technical","text":""},{"location":"faq/technical/#how-can-i-reset-the-administrator-password","title":"How can I reset the administrator password?","text":"<p>Kubernetes install (Helm):</p> <pre><code>$ kubectl -n kubedash exec $(kubectl -n kubedash get pods -l app=kubedash | grep '1/1' | head -1 | awk '{ print $1 }') -- flask commands reset-password\nNew password for default administrator (admin):\n&lt;new_password&gt;\n</code></pre>"},{"location":"functions/authentication/","title":"Authentication","text":""},{"location":"functions/authentication/#first-log-in","title":"First Log In","text":"<p>To log in for the first time the default user and password is <code>admin</code> <code>admin</code>. After you log into the web-ui you will alert to change the default admin password.</p> <p></p>"},{"location":"functions/authentication/#authentication","title":"Authentication","text":"<p>One of the key features that KubeDash adds to Kubernetes is centralized user management. This feature allows to set up local users and/or connect to an external OIDC authentication provider. By connecting to an external authentication provider, you can leverage that provider's user and groups.</p>"},{"location":"functions/authentication/#reset-admin-password","title":"Reset Admin Password","text":"<p>You can reset the admin password of the application from commandline:</p> <pre><code>kubectl exec -it kubedash-bd959b784-ldd4t bash\n$ flask cli reset-password\nNew password for default administrator (admin): admin\nadmin\nUser Updated Successfully\n</code></pre> <p></p>"},{"location":"functions/authentication/#configure-oidc-provider","title":"Configure OIDC provider","text":"<p>To add an OIDC provider to KubeDash go to <code>Settings &gt; Auth Provider</code>:</p> Parameter Description Redirect URI <code>https://yourKubDashHostURL</code> Identity Provider URL The URL of your IdP. Identity Provider Client ID The <code>Client ID</code> of your IdP client. Identity Provider Client Secret The generated <code>Secret</code> of your IdP client. <p></p>"},{"location":"functions/authentication/#authorization","title":"Authorization","text":"<p>Once an user logged in to KubeDash the their access rights within the system, is determined by the user's role. There i two role in KubeDash User and Admin. This role determinate what you can configure in KubeDash. </p>"},{"location":"functions/authentication/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<p>From kubernetes perspective all of your privileges are determined by Role-Based Access Control (RBAC). The KubeDash Admin role allow you to use the KubeDash pod's cluster-admin ServiceAccount for the interactions with the kubernetes API. </p> <p>With the Local role KubeDash use your OIDC token for the same purpose, so you have the same privileges as in the cli.</p> <p>You can manage Roles from the KubDash UI. See in the next section for more information.</p>"},{"location":"functions/features/","title":"Features","text":"<ul> <li>Manage any Kubernetes cluster.</li> <li>User management.</li> <li>Kubernetes User creation</li> <li>Kubectl configuration generation for Kubernetes User</li> <li>Single sign-on integration with authentication and authorization</li> <li>Kubectl configuration generation with Oauth2 Authentication</li> <li>kubectl plugin</li> <li>CPU and Memory metrics visualization.</li> <li>Hem Chart listing</li> <li>trivy-operator integration to visualize vulnerability</li> <li>Beta:</li> <li>Visualization of Resources for specific namespaces.</li> <li>Log streaming of a workload or service.</li> </ul>"},{"location":"functions/k8s-api/","title":"Setting up Kubernetes Clusters in KubeDash","text":""},{"location":"functions/k8s-api/#configure-kubernetes-cluster-connection","title":"Configure Kubernetes cluster connection","text":"<p>To add a Kubernetes Cluster to KubeDash go to <code>Settings &gt; Cluster Configuration</code> and Click <code>New</code>:</p> Parameter Description Kubernetes Config Context The name of the cluster context Kubernetes API URL <code>https://yourKubernetesHostURL:8443</code> Kubernetes CA Certificate Certificate <p>Select <code>Add</code> to create the Kubernetes connection. You can add only one cluster for KubeDash. To edit the cluster select the pencil icon next to the line of the cluster.</p> <p></p>"},{"location":"functions/kubectl-config/","title":"Download Kubectl Config for your user","text":"<p>In KubeDash you can download your kubectl configuration in your profile menu: </p> <p></p> <p>The configuration is differs based on the user type:</p> <ul> <li>The SSO users gat a config for SSO authentication.</li> <li>The local users gat a config for with certificate based authentication. The KubeDash Dashboard generates the certificate.</li> </ul> <p> </p>"},{"location":"functions/rbac/","title":"Users","text":"<p>Within KubDash, each person authenticates as a user, which is a login that grants you access to KubDash. As mentioned in Authentication, users can either be local or external.</p>"},{"location":"functions/rbac/#manage-user-roles","title":"Manage User Roles","text":"<p>KuDash enables a super-easy and user-friendly RBAC management for users in Kubernetes. If you are looking for a simple and intuitive way of managing your users within a Kubernetes cluster, this is the right place.</p> <p>With KuDash, you can create users, assign namespaces/permissions, via a nice and easy web UI.</p> <p></p>"},{"location":"functions/rbac/#manage-group-roles","title":"Manage Group Roles","text":"<p>KuDash automatically creates groups from SSO login information. You can map this groups with Role templates.</p> <p></p>"},{"location":"functions/rbac/#edit-kubernetes-roles-and-role-bindings","title":"Edit Kubernetes Roles and Role bindings","text":"<p>KuDash enables a super-easy and user-friendly RBAC management for Kubernetes. If you are looking for a simple and intuitive way of managing your users within a Kubernetes cluster, this is the right place.</p> <p>With KuDash, you can create users, assign namespaces/permissions, and distribute Kubeconfig YAML files via a nice and easy web UI.</p> <p></p> <p>The application allows us to define and select permission-templates and associate them with all the users you might want to create. This configuration can be applied, within a namespace or globally. The template system is an abstraction over Cluster-Roles, RoleBinding, and ClusterRolesBindigs. A template is a ClusterRole with a prefix <code>template-namespaced-resources---</code> for example <code>template-namespaced-resources---developer</code></p> <p>The fallowing ClusterRoles are the default templates:</p> <ul> <li><code>template-cluster-resources\u2014--admin</code> - Custer Admin privilege to use in cluster role bindings.</li> <li><code>template-cluster-resources\u2014--reader</code> - Cluster Read only privilege to use in cluster role bindings.</li> <li><code>template-namespaced-resources\u2014--deployer</code> - Deployer privilege for technical users to use in cluster role bindings.</li> <li><code>template-namespaced-resources\u2014--developer</code> - Developer  privilege for developers to use in role bindings.</li> <li><code>template-namespaced-resources\u2014--operation</code> - Namespace Admin privilege to use in role bindings.</li> </ul> <p>You can create your own templates by creating a clusterRole starting with the <code>template-namespaced-resources---</code> prefix. KubeDash will automatically detect your custom templates.</p>"},{"location":"functions/resource-map/","title":"Resource Map","text":"<p>With the Resource Map function you can visualize the connections of the Kubernetes objects in a namespace:</p> <p></p>"},{"location":"functions/users/","title":"User Management","text":"<p>KubeDash use OIDC as its main authentication mechanism but from KubeDash 2.0 you can create local users from the UI and convert them into Kubernetes users. With this solution Kubernetes will use certificate based authentication. The benefit of this approach date you can authenticate without a working OIDC Identity Provider so it is perfect for admin users.</p> <p>You can manage your users under the <code>User Management &gt; Users</code> menu:</p> <p></p> <p>You can Create a new user wit the <code>Add User</code> button:</p> <p></p> <p>You can change the type of an existing user with the pencile icon next to the user:</p> <p></p>"},{"location":"functions/users/#roles","title":"Roles","text":"<p>The role of the user decides the ability of the user to manage dashboard users. There is two roles the <code>User</code> role and the <code>Admin</code> role. Only the users with <code>Admin</code> role can create or adit dashboard users.</p>"},{"location":"functions/users/#user-types","title":"User Types","text":"<p>There is tree user types:</p> <ul> <li>OpenID - Automatically created SSO users.</li> <li>Local - Manually created, stored in database without Kubernetes authentication.</li> <li>Kubernetes - Manually created, stored in database with certificate based Kubernetes authentication.</li> </ul>"},{"location":"installation/configuration/","title":"Configuration","text":"<p>Create a values file for your helm deploy:</p> <pre><code># -- Time Zone in container\nTimeZone: \"CET\"\n# -- Log level\nlogLevel: \"INFO\"\n# -- flask environment: production or development\nflaskConfig: \"production\"\n\nserviceAccount:\n  # -- Enable automatic serviceAccount creation\n  create: true\n  # -- Configure the name of the serviceAccount\n  name: \"kubedash-admin\"\n\nimage:\n  # -- The docker image repository to use\n  repository: devopstales/kubedash\n  # -- Configure the pull policy\n  pullPolicy: Always\n  # -- The docker image tag to use\n  tag: 3.1.0\n\n# -- pullsecrets\nimagePullSecrets: []\n\n# -- replica number - for multiple replicas you need to enable externalDatabase support\nreplicas: 1\n\n# -- enable external postgresql support\nexternalDatabase:\n  enabled: false\n  host: \"\"\n  port: 5432\n  database: \"kubedash\"\n  username: \"kubedash-user\"\n  password: \"kubedash-pass\"\n  secret:\n    # -- Name of the secret storing EXTERNAL_DATABASE_PASSWORD.\n    name: \"kubedash-postgresql\"\n    # -- Secret must provide the following variables: EXTERNAL_DATABASE_PASSWORD.\n    useExistingSecret: false\n\n# -- deploy HA postgresql\npostgresqlHa:\n  enabled: false\n  rbac:\n    create: true\n  persistence:\n    enabled: true\n#    storageClass: default\n  postgresql:\n    database: \"kubedash\"\n    username: \"kubedash-user\"\n    password: \"kubedash-pass\"\n    repmgrPassword: \"change-me\"\n    postgresPassword: \"change-me\"\n  pgpool:\n    replicaCount: 2\n    adminPassword: \"change-me\"\n  metrics:\n    enabled: true\n    serviceMonitor:\n      enabled: false\n# https://artifacthub.io/packages/helm/bitnami/postgresql-ha\n\n# -- enable metrics-server\nmetricsServer:\n  enabled: false\n  args:\n    - --kubelet-preferred-address-types=InternalIP\n    - --kubelet-insecure-tls\n\n# -- k8s connection information.\ncluster:\n  # -- k8s api url\n  name: \"k8s-cluster\"\n  # -- k8s api url\n  apiUrl: \"https://kubernetes.mydomain.intra:6443\"\n  # `apiServer` is the url for kubectl\n  #   This is typically  https://api.fqdn\n  # -- k8s ca cert\n  caCert: |-\n    -----BEGIN CERTIFICATE-----\n    cert data here\n    -----END CERTIFICATE-----\n  # `caCrt` is the public / CA cert for the cluster\n  # cat /etc/kubernetes/pki/ca.crt\n\n# -- oidc connection information\noidc:\n  # -- Enable oidc authentication\n  enabled: false\n  provider:\n    # -- oidc issuer url\n    oidcUrl: \"https://sso.mydomain.intra/auth/realms/k8s\"\n    # -- oidc scope\n    oidcScopes: \"openid email\"\n    # -- oidc client id\n    oidcClientId: \"\"\n    # -- oidc client secret\n    oidcSecret: \"\"\n  secret:\n    # -- Name of the secret storing OIDC_CLIENT_ID and OIDC_SECRET.\n    name: \"kubedash-oidc\"\n    # -- Secret must provide the following variables: OIDC_CLIENT_ID and OIDC_SECRET.\n    useExistingSecret: false\n\n# -- enable plugins\nplugins:\n  registryUi:\n    # -- Enable registry UI plugin with set PLUGIN_REGISTRY_ENABLED\n    enabled: false\n  helmDashboard:\n    # -- Enable helm dashboard plugin with set PLUGIN_HELM_ENABLED\n    enabled: true\n\npersistence:\n  # -- Volumes for the pod\n  enabled: true\n  # -- Volumes mode\n  accessMode: \"ReadWriteOnce\"\n  # -- Volumes size\n  size: \"1Gi\"\n  # -- Volumes annotations\n  annotations: {}\n  ## database data Persistent Volume Storage Class\n  ## If defined, storageClassName: &lt;storageClass&gt;\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS &amp; OpenStack)\n  ##\n  # storageClass: \"-\"\n\ningress:\n  # -- Enable Ingress object creation\n  enabled: true\n  # -- Ingress class name\n  className: \"nginx\"\n  # -- URL of the Ingress object\n  url: \"kubedash.mydomain.intra\"\n  # -- Extra annotation to the Ingress object\n  annotations:\n    nginx.ingress.kubernetes.io/proxy-body-size: \"10m\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"3600\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"3600\"\n    nginx.ingress.kubernetes.io/server-snippets: |\n      location / {\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_http_version 1.1;\n        proxy_set_header X-Forwarded-Host $http_host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host $host;\n        proxy_set_header Connection \"upgrade\";\n        proxy_cache_bypass $http_upgrade;\n      }\n  tls:\n    # -- Enable tls on Ingress object\n    enabled: true\n    # -- Name of the secret storing tls cert\n    tlsSecret: \"\"\n    certManager:\n       # -- Enable certManager\n      enabled: false\n      # -- Name of the certManager cluster issuer to use\n      clusterIssuer: \"letsencrypt\"\n  whitelist:\n    # -- Enable ip blocking on ingress\n    enabled: false\n    # -- List of ips to allow communication\n    ips: []\n\nroute:\n  # -- Enable OpenShift Route object creation\n  enabled: false\n  # -- URL of the OpenShift Route object\n  url: \"kubedash.mydomain.intra\"\n  # -- Extra annotation to the OpenShift Route object\n  annotations: {}\n\n# -- list of the pos's SecurityContexts\npodSecurityContext:\n  runAsNonRoot: true\n  runAsUser: 10001\n  fsGroup: 10001\n  fsGroupChangePolicy: \"OnRootMismatch\"\n\n# -- list of the container's SecurityContexts\ncontainerSecurityContext:\n  allowPrivilegeEscalation: false\n  capabilities:\n    drop: [\"all\"]\n\n## Define which Nodes the Pods are scheduled on.\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n# -- Set nodeSelector for the pod\nnodeSelector: {}\n\n## Tolerations for use with node taints\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n# -- Set tolerations for the pod\ntolerations: []\n# - key: \"key\"\n#   operator: \"Equal\"\n#   value: \"value\"\n#   effect: \"NoSchedule\"\n\n## Assign custom affinity rules to the trivy operator\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n##\n\n## Assign custom affinity rules to the deployment\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n# -- Set the affinity for the pod.\naffinity: {}\n# nodeAffinity:\n#   requiredDuringSchedulingIgnoredDuringExecution:\n#     nodeSelectorTerms:\n#     - matchExpressions:\n#       - key: kubernetes.io/e2e-az-name\n#         operator: In\n#         values:\n#         - e2e-az1\n#         - e2e-az2\n</code></pre>"},{"location":"installation/configuration/#operator-configuration","title":"Operator Configuration","text":"<p>The following tables lists configurable parameters of the trivy-operator chart and their default values.</p>"},{"location":"installation/configuration/#values","title":"Values","text":"Key Type Default Description TimeZone string <code>\"CET\"</code> Time Zone in container affinity object <code>{}</code> Set the affinity for the pod. cluster object <code>{\"apiUrl\":\"https://kubernetes.mydomain.intra:6443\",\"name\":\"k8s-cluster\"}</code> k8s connection information. cluster.apiUrl string <code>\"https://kubernetes.mydomain.intra:6443\"</code> k8s api url cluster.name string <code>\"k8s-cluster\"</code> k8s api url containerSecurityContext object <code>{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"all\"]}}</code> list of the container's SecurityContexts createClusterRole bool <code>true</code> Enable ClusterRole creation. Disable if the role already exists. dbui object <code>{\"image\":{\"plugins\":\"tables-filter,adminer-auto-login\",\"pullPolicy\":\"IfNotPresent\",\"repository\":\"sosedoff/pgweb\",\"tag\":\"latest\"}}</code> deploy ui for db dbui.image.plugins string <code>\"tables-filter,adminer-auto-login\"</code> adminer plugins dbui.image.pullPolicy string <code>\"IfNotPresent\"</code> adminer image pull policy dbui.image.repository string <code>\"sosedoff/pgweb\"</code> adminer image dbui.image.tag string <code>\"latest\"</code> adminer image tag externalDatabase object <code>{\"database\":\"kubedash\",\"enabled\":false,\"host\":\"\",\"password\":\"kubedash\",\"port\":5432,\"secret\":{\"name\":\"kubedash-postgresql\",\"useExistingSecret\":false},\"username\":\"kubedash\"}</code> enable external postgresql support externalDatabase.database string <code>\"kubedash\"</code> External postgresql database externalDatabase.enabled bool <code>false</code> Enable external postgresql externalDatabase.host string <code>\"\"</code> External postgresql host externalDatabase.password string <code>\"kubedash\"</code> External postgresql password externalDatabase.port int <code>5432</code> External postgresql port externalDatabase.secret.name string <code>\"kubedash-postgresql\"</code> Name of the secret storing EXTERNAL_DATABASE_PASSWORD. externalDatabase.secret.useExistingSecret bool <code>false</code> Secret must provide the following variables: EXTERNAL_DATABASE_PASSWORD. externalDatabase.username string <code>\"kubedash\"</code> External postgresql username flaskConfig string <code>\"production\"</code> flask environment: production or development image.pullPolicy string <code>\"Always\"</code> The docker image pull policy image.repository string <code>\"devopstales/kubedash\"</code> The docker image repository to use image.statsdExporter.repository string <code>\"prom/statsd-exporter\"</code> The docker image repository to use image.statsdExporter.tag string <code>\"v0.22.4\"</code> The docker image tag to use image.tag string <code>\"3.1.0\"</code> The docker image tag to use imagePullSecrets list <code>[]</code> pullsecrets ingress.annotations object <code>{\"nginx.ingress.kubernetes.io/proxy-body-size\":\"10m\",\"nginx.ingress.kubernetes.io/proxy-read-timeout\":\"3600\",\"nginx.ingress.kubernetes.io/proxy-send-timeout\":\"3600\",\"nginx.ingress.kubernetes.io/server-snippets\":\"location / {\\n  proxy_set_header Upgrade $http_upgrade;\\n  proxy_http_version 1.1;\\n  proxy_set_header X-Forwarded-Host $http_host;\\n  proxy_set_header X-Forwarded-Proto $scheme;\\n  proxy_set_header X-Forwarded-For $remote_addr;\\n  proxy_set_header Host $host;\\n  proxy_set_header Connection \\\"upgrade\\\";\\n  proxy_cache_bypass $http_upgrade;\\n}\\n\"}</code> Extra annotation to the Ingress object ingress.className string <code>\"nginx\"</code> Ingress class name ingress.enabled bool <code>true</code> Enable Ingress object creation ingress.tls.certManager.clusterIssuer string <code>\"letsencrypt\"</code> Name of the certManager cluster issuer to use ingress.tls.certManager.enabled bool <code>false</code> Enable certManager ingress.tls.enabled bool <code>true</code> Enable tls on Ingress object ingress.tls.tlsSecret string <code>\"\"</code> Name of the secret storing tls cert ingress.url string <code>\"kubedash.mydomain.intra\"</code> URL of the Ingress object ingress.whitelist.enabled bool <code>false</code> Enable ip blocking on ingress ingress.whitelist.ips list <code>[]</code> List of ips to allow communication logLevel string <code>\"INFO\"</code> Log level metrics.enabled bool <code>true</code> Enable metrics metrics.grafana.annotations.grafana_folder string <code>\"KubeDash\"</code> metrics.grafana.enabled bool <code>true</code> Enable grafana dashboard deploy metrics.grafana.labels.grafana_dashboard string <code>\"1\"</code> metrics.grafana.namespace string <code>\"monitoring-system\"</code> Grafana dashboard namespace metrics.serviceMonitor.annotations object <code>{}</code> Prometheus service monitor annotations metrics.serviceMonitor.enabled bool <code>false</code> Enable prometheus service monitor metrics.serviceMonitor.honorLabels object <code>{}</code> metrics.serviceMonitor.interval string <code>\"30s\"</code> Prometheus service monitor interval metrics.serviceMonitor.jobLabel object <code>{}</code> Prometheus service monitor job labels metrics.serviceMonitor.labels object <code>{\"release\":\"kube-prometheus-stack\"}</code> Prometheus service monitor labels metrics.serviceMonitor.metricRelabelings list <code>[]</code> metrics.serviceMonitor.relabelings list <code>[]</code> metrics.serviceMonitor.scrapeTimeout string <code>\"10s\"</code> Prometheus service monitor scrape timeout metricsServer object <code>{\"args\":[\"--kubelet-preferred-address-types=InternalIP\",\"--kubelet-insecure-tls\"],\"enabled\":false}</code> enable metrics-server nodeSelector object <code>{}</code> Set nodeSelector for the pod oidc object <code>{\"enabled\":false,\"provider\":{\"oidcClientId\":\"\",\"oidcScopes\":\"openid email\",\"oidcSecret\":\"\",\"oidcUrl\":\"https://sso.mydomain.intra/auth/realms/k8s\"},\"secret\":{\"name\":\"kubedash-oidc\",\"useExistingSecret\":false}}</code> oidc connection information oidc.enabled bool <code>false</code> Enable oidc authentication oidc.provider.oidcClientId string <code>\"\"</code> oidc client id oidc.provider.oidcScopes string <code>\"openid email\"</code> oidc scope oidc.provider.oidcSecret string <code>\"\"</code> oidc client secret oidc.provider.oidcUrl string <code>\"https://sso.mydomain.intra/auth/realms/k8s\"</code> oidc issuer url oidc.secret.name string <code>\"kubedash-oidc\"</code> Name of the secret storing OIDC_CLIENT_ID and OIDC_SECRET. oidc.secret.useExistingSecret bool <code>false</code> Secret must provide the following variables: OIDC_CLIENT_ID and OIDC_SECRET. persistence object <code>{\"accessMode\":\"ReadWriteOnce\",\"annotations\":{},\"enabled\":true,\"size\":\"1Gi\",\"storageClass\":\"-\"}</code> enable persistence persistence.accessMode string <code>\"ReadWriteOnce\"</code> Volumes mode persistence.annotations object <code>{}</code> Volumes annotations persistence.enabled bool <code>true</code> Volumes for the pod persistence.size string <code>\"1Gi\"</code> Volumes size plugins object <code>{\"certManager\":{\"enabled\":true},\"externalLoadbalancer\":{\"enabled\":true},\"flux\":{\"enabled\":true},\"helmDashboard\":{\"enabled\":true},\"registryUi\":{\"enabled\":true}}</code> enable plugins plugins.certManager.enabled bool <code>true</code> Enable helm dashboard plugin plugins.externalLoadbalancer.enabled bool <code>true</code> Enable external loadbalancer plugin plugins.flux.enabled bool <code>true</code> Enable flux plugin plugins.helmDashboard.enabled bool <code>true</code> Enable helm dashboard plugin plugins.registryUi.enabled bool <code>true</code> Enable registry UI plugin podSecurityContext object <code>{\"fsGroup\":10001,\"fsGroupChangePolicy\":\"OnRootMismatch\",\"runAsNonRoot\":true,\"runAsUser\":10001}</code> list of the pos's SecurityContexts postgresql object <code>{\"auth\":{\"database\":\"kubedash\",\"password\":\"kubedash\",\"postgresPassword\":\"change-me\",\"replicationPassword\":\"change-me\",\"username\":\"kubedash\"},\"enabled\":true,\"metrics\":{\"enabled\":true,\"serviceMonitor\":{\"enabled\":false,\"honorLabels\":{},\"jobLabel\":{},\"labels\":{\"release\":\"kube-prometheus-stack\"}}},\"primary\":{\"persistence\":{\"size\":\"10Gi\"}},\"rbac\":{\"create\":true},\"readReplicas\":{\"replicaCount\":0},\"securityContext\":{\"enabled\":false},\"shmVolume\":{\"chmod\":{\"enabled\":false}},\"volumePermissions\":{\"enabled\":false,\"securityContext\":{\"runAsUser\":\"auto\"}}}</code> deploy postgresql postgresql.auth.database string <code>\"kubedash\"</code> Postgresql database postgresql.auth.password string <code>\"kubedash\"</code> Postgresql password postgresql.auth.postgresPassword string <code>\"change-me\"</code> Postgresql postgres user password postgresql.auth.replicationPassword string <code>\"change-me\"</code> Postgresql replication password postgresql.auth.username string <code>\"kubedash\"</code> Postgresql username postgresql.enabled bool <code>true</code> Enable postgresql postgresql.metrics.enabled bool <code>true</code> Enable postgresql metrics postgresql.metrics.serviceMonitor.enabled bool <code>false</code> Enable prometheus service monitor postgresql.metrics.serviceMonitor.jobLabel object <code>{}</code> Set serviceMonitor labels postgresql.metrics.serviceMonitor.labels object <code>{\"release\":\"kube-prometheus-stack\"}</code> Prometheus service monitor labels postgresql.readReplicas.replicaCount int <code>0</code> Number of read replicas to create postgresql.securityContext.enabled bool <code>false</code> Enable postgresql security context postgresql.shmVolume.chmod object <code>{\"enabled\":false}</code> Enable postgresql shared memory volume postgresql.volumePermissions.enabled bool <code>false</code> Enable init container to set permissions on data volume redis object <code>{\"architecture\":\"standalone\",\"enabled\":true,\"metrics\":{\"enabled\":true,\"serviceMonitor\":{\"additionalLabels\":{\"release\":\"kube-prometheus-stack\"},\"enabled\":false}}}</code> enable redis for caching redis.architecture string <code>\"standalone\"</code> Redis cluster architecture redis.enabled bool <code>true</code> Enable redis redis.metrics.enabled bool <code>true</code> Enable redis metrics redis.metrics.serviceMonitor.additionalLabels object <code>{\"release\":\"kube-prometheus-stack\"}</code> Prometheus service monitor namespace namespace: \"monitoring\" redis.metrics.serviceMonitor.enabled bool <code>false</code> Enable prometheus service monitor redisui object <code>{\"image\":{\"pullPolicy\":\"Always\",\"repository\":\"patrikx3/p3x-redis-ui\",\"tag\":\"latest\"},\"resources\":{}}</code> redis ui replicas int <code>1</code> replica number - for multiple replicas you need to enable externalDatabase support route.annotations object <code>{}</code> Extra annotation to the OpenShift Route object route.enabled bool <code>false</code> Enable OpenShift Route object creation route.url string <code>\"kubedash.mydomain.intra\"</code> URL of the OpenShift Route object serviceAccount.create bool <code>true</code> Enable automatic serviceAccount creation serviceAccount.name string <code>\"kubedash-admin\"</code> Configure the name of the serviceAccount tolerations list <code>[]</code> Set tolerations for the pod"},{"location":"installation/installation/","title":"Installation","text":""},{"location":"installation/installation/#before-you-begin","title":"Before you Begin","text":"<p>You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with your cluster. If you do not already have a cluster, you can create one by installing minikube, kind or microk8s, or you can use the following Kubernetes playground.</p>"},{"location":"installation/installation/#helm","title":"Helm","text":"<p>Helm, which is a popular package manager for Kubernetes, allows installing applications from parameterized YAML manifests called Helm charts.</p>"},{"location":"installation/installation/#installing-from-the-devopstales-chart-repository","title":"Installing from the DevOpsTales Chart Repository","text":"<pre><code>helm repo add devopstales https://devopstales.github.io/helm-charts\nhelm repo update\nhelm upgrade --install kubedash devopstales/kubedash\n</code></pre> <p>Tip: List all releases using <code>helm list</code>.</p>"},{"location":"installation/installation/#advanced-configuration","title":"Advanced Configuration","text":"<p>The command deploys kubedash on the Kubernetes cluster in the default configuration. The Parameters section lists the parameters that can be configured during installation.</p>"},{"location":"installation/installation/#uninstall","title":"Uninstall","text":"<p>You can uninstall the operator with the following command:</p> <pre><code>helm uninstall kubedash\n</code></pre>"},{"location":"installation/platforms/","title":"Platforms","text":""},{"location":"installation/platforms/#tested-kubernetes-platforms","title":"Tested Kubernetes Platforms","text":"<p>This section shows the different platforms where KubeDash has been tested or is intended to be tested, and useful observations about it. If you have tested KubeDash on a different flavor or Kubernetes, please file a PR or issue to add your remarks to the list.</p> <p>The \"works\" column refers to the overall Kubernetes related functionality when running in the respective platform; it may have 3 different values:</p> <ul> <li>\u2714\ufe0f : Has been tried and works fine to the extent of what has been tested</li> <li>\u274c : Has been tried and didn't work or had issues that prevented a regular use of it</li> <li>\u2754: Hasn't been tried/reported yet</li> </ul> Platform Works Comments Amazon EKS \u2714\ufe0f - Simple to install Google Kubernetes Engine (GKE) \u2714\ufe0f - Simple to install Microsoft AKS \u2714\ufe0f - Simple to install DigitalOcean Kubernetes \u2754 - Have you tried KubeDash on this platform? Please report your experience. K3s \u2714\ufe0f - Simple to install Kind \u2714\ufe0f - Simple to install Minikube \u2714\ufe0f - For exposing with an ingress, enable ingresses with <code>minikube addons enable ingress</code> RKE2 \u2714\ufe0f - Simple to install Lokomotive \u2754 - Have you tried KubeDash on this platform? Please report your experience. Vultr Kubernetes Engine \u2754 - Have you tried KubeDash on this platform? Please report your experience."},{"location":"installation/platforms/#tested-browsers","title":"Tested Browsers","text":"<p>We mostly test with 'modern browsers' defined as the latest version and two older versions. But we try to make KubeDash work with web standards, so it's quite likely other standards conforming browsers will also work.</p> Platform Works Comments Edge \u2714\ufe0f Safari \u2714\ufe0f Firefox \u2714\ufe0f Chrome \u2714\ufe0f Internet Explorer 11 \u2714\ufe0f"},{"location":"integrations/cert-manager/","title":"Cert-Manager Plugin","text":"<p>Whit the KubeDatabase UI you can see your <code>Cert-Manager</code> Custom configurations and there sates.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"integrations/docker-registry/","title":"Docker Registry Integration","text":"<p>From KubeDash 2.0 you can configure your dashboard as a Docker Registry UI:</p> <p></p> <p></p>"},{"location":"integrations/docker-registry/#using-cors","title":"Using CORS","text":"<p>Your server should be configured to accept CORS.</p> <p>If your docker registry does not need credentials, you will need to send this HEADER:</p> <pre><code>Access-Control-Allow-Origin: ['*']\n</code></pre> <p>If your docker registry need credentials, you will need to send these HEADERS (you must add the protocol <code>http</code>/<code>https</code> and the port when not default <code>80</code>/<code>443</code>):</p> <pre><code>http:\n  headers:\n    Access-Control-Allow-Origin: ['http://registry.example.com']\n    Access-Control-Allow-Credentials: [true]\n    Access-Control-Allow-Headers: ['Authorization', 'Accept', 'Cache-Control']\n    Access-Control-Allow-Methods: ['HEAD', 'GET', 'OPTIONS'] # Optional\n</code></pre>"},{"location":"integrations/docker-registry/#enable-delete","title":"Enable delete","text":"<p>For deleting images, you need to activate the delete feature in the UI with <code>DELETE_IMAGES=true</code> and in your registry:</p> <pre><code>storage:\n    delete:\n      enabled: true\n</code></pre> <p>And you need to add these HEADERS:</p> <pre><code>http:\n  headers:\n    Access-Control-Allow-Methods: ['HEAD', 'GET', 'OPTIONS', 'DELETE']\n    Access-Control-Allow-Headers: ['Authorization', 'Accept', 'Cache-Control']\n    Access-Control-Expose-Headers: ['Docker-Content-Digest']\n</code></pre>"},{"location":"integrations/docker-registry/#basic-authentication","title":"Basic Authentication","text":"<p>Enable authentication in the registry config:</p> <pre><code>auth:\n  htpasswd:\n    realm: basic-realm\n    path: /etc/docker/registry/htpasswd\n</code></pre> <p>Then add the Registry at <code>OCI Registrys &gt; Add Registry</code></p> <p></p> <p></p>"},{"location":"integrations/docker-registry/#registry-events","title":"Registry Events","text":"<p>If your Registry supports sending webhook notifications in response to events happening within the registry, then the KubeDash can store this events in its database and visualize.</p> <pre><code>notifications:\n  endpoints:\n    - name: kubedash\n      url: https://kubedash.mydomain.intra/plugins/registry/events\n      timeout: 1s\n      threshold: 5\n      backoff: 10s\n      ignoredmediatypes:\n        - application/octet-stream\n</code></pre> <p></p>"},{"location":"integrations/docker-registry/#image-tagging","title":"Image Tagging","text":""},{"location":"integrations/docker-registry/#image-lableing","title":"Image Lableing","text":"<p>The Doker registry UI can show stander docker labels based on common standards:</p> <ul> <li>https://specs.opencontainers.org/image-spec/annotations/</li> <li>http://label-schema.org/rc1/</li> </ul>"},{"location":"integrations/docker-registry/#oci-helm-charts","title":"OCI Helm Charts","text":"<p>If you use an OCI compatible Docker Registry you can store your Helm chart in OCI format. With KubeDash, you can visualize the Helm Chart metadata:</p> <p></p>"},{"location":"integrations/docker-registry/#image-security-sbom","title":"Image Security SBOM","text":"<p>SBOMs can also be stored in an OCI registry, using OCI specification:</p> <pre><code>trivy i --format cosign-vuln \\\nregistry.mydomain.intra:5000/registry-imega-test:1.0 &gt; image.sbom\n\ncosign attach sbom --sbom image.sbom \\\nregistry.mydomain.intra:5000/registry-imega-test:1.0\n</code></pre> <p></p>"},{"location":"integrations/external-load-balancer/","title":"External LoadBalancer Plugin","text":"<p>Whit the KubeDatabase UI you can see your <code>External LoadBalancer</code> configurations and there sates. Currently the two supported loadbalancing application is <code>MetalLB</code> and <code>Clilium</code>.</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"integrations/helm/","title":"HelmChart","text":"<p>KubeDash offers a UI-driven way to view the installed Helm charts, see their revision history and corresponding k8s resources.</p> <p>Key capabilities of the tool:</p> <ul> <li>See all installed charts and their revision history</li> <li>Browse k8s resources resulting from the chart</li> </ul> <p></p>"},{"location":"integrations/kubectl-plugin/","title":"Kubectl Plugin","text":"<p>Kubectl has the ability to extend it's functionality with plugins. To ease the download and installation of the kubectl config KubeDash offers a simple kubectl plugin for login. I will open the login page automatically in the browser and merge the configuration to the local kubectl config.</p>"},{"location":"integrations/kubectl-plugin/#install-kubectl-plugin","title":"Install Kubectl plugin","text":"<pre><code># Homebrew (macOS and Linux)\nbrew tap devopstales/devopstales\nbrew install kubectl-kdlogin\n\n# My krew repo (macOS, Linux, Windows and ARM)\nkubectl krew index add devopstales https://github.com/devopstales/krew\nkubectl krew install devopstales/kdlogin\n\n# Chocolatey (Windows)\nchoco install kubectl-kdlogin\n\n# Binary release (Windows, macOS and Linux)\nhttps://github.com/devopstales/kubedash/releases\n</code></pre>"},{"location":"integrations/kubectl-plugin/#use-the-plugin","title":"Use the plugin","text":"<pre><code>$ kubectl kdlogin /\nConfigfile created with config for productioncluster to ~/.kube/config\nHappy Kubernetes interaction!\n</code></pre>"},{"location":"integrations/project-data/","title":"Project Data","text":"<p>Project specific information can be stored in the namespace level that the Dashboard will visualize.</p> Annotation Description <code>metadata.k8s.io/owner</code> username <code>metadata.k8s.io/description</code> Unstructured text description of the service for humans. <code>metadata.k8s.io/chat</code> Slack channel (prefix with #), or link to other external chat system. <code>metadata.k8s.io/bugs</code> Link to external bug tracker. <code>metadata.k8s.io/documentation</code> Link to external project documentation. <code>metadata.k8s.io/repository</code> Link to external VCS repository. <code>metadata.k8s.io/pipeline</code> Link to external CI/CD. <code>metadata.k8s.io/egress-ip</code> ehgress ip if ns specific <code>metadata.k8s.io/ingress-ip</code> ingress ip if ns specific <p>Based on Example: https://ambassadorlabs.github.io/k8s-for-humans/</p>"},{"location":"integrations/trivy-operator/","title":"trivy-operator integration","text":"<p>KubeDash can integrate with my original trivy-operator and aquasecurity's official operator to show vulnerabilities in your cluster. Kubdash automatically detects the VulnerabilityReport Custom Resource Objects created by trivy-operator.</p> <p>You can find the vulnerabilities on the pod page: </p> <p>Then the full list of vulnerabilities are shown below the container data: </p>"}]}